{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2824b7d852407cba1c30e1cd95848b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# huggingface login\n",
    "# Get your token from huggingface.co/settings/tokens\n",
    "from huggingface_hub import login\n",
    "login()  # This will prompt for your token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from outlines import models, generate\n",
    "# pip install outlines transformers datasets\n",
    "\n",
    "model = models.transformers(\"facebook/opt-iml-max-1.3b\")\n",
    "\n",
    "generator = generate.regex(\n",
    "    model,\n",
    "    r\"((25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the IP address of the Google DNS servers? \"\n",
    "answer = generator(prompt, max_tokens=30)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with 2 \"training\" and 1 \"test\"\n",
    "        #   - Certain times are completely unavailable (e.g., sleep, existing meetings).\n",
    "        #   - Some times are less ideal (e.g., early morning or late evening).\n",
    "        #   - Certain times are optimal for scheduling activities (e.g., typical work hours or daylight hours).\n",
    "\n",
    "        # You will be given some examples, and then a new context prompt. Your task is to generate a cost table for the new context prompt. Only return the array of numbers.\n",
    "\n",
    "        # param: *context_prompt*: includes existing meetings, preferences, and constraints\n",
    "\n",
    "    # prompt = \"\"\"\n",
    "\n",
    "    # TASK DESCRIPTION:\n",
    "    #     Generate 24-hour cost table that aligns with natural language constraints and preferences for scheduling activities.\n",
    "\n",
    "    #        - Certain times are completely unavailable (e.g., sleep, existing meetings).\n",
    "    #        - Some times are less ideal (e.g., early morning or late evening).\n",
    "    #        - Certain times are optimal for scheduling activities (e.g., typical work hours or daylight hours).\n",
    "\n",
    "    #      You will be given some examples, and then a new context prompt. Your task is to generate a cost table for the new context prompt. Only return the 24-hours cost table array of numbers.\n",
    "\n",
    "    #     param: *context_prompt*: includes existing meetings, preferences, and constraints\n",
    "    #     Examples:\n",
    "\n",
    "    # \"context_prompt\":\n",
    "    # \"From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.\"\n",
    "    # \"goal\": \"Generate an array for a 24-hour cost table where each hour reflects its scheduling cost based on the constraints provided.\"\n",
    "    # ”cost_table”: [\n",
    "    #     1000, 1000, 1000, 1000, 1000, 1000, 1000,  # 12:00 AM to 6:59 AM\n",
    "    #     50, 50,  # 7:00 AM to 8:59 AM\n",
    "    #     float('inf'), float('inf'), float('inf'), float('inf'), float('inf'),  # 9:00 AM to 2:00 PM\n",
    "    #     0,  # 2:00 PM to 2:59 PM\n",
    "    #     float('inf'),  # 3:00 PM to 3:59 PM\n",
    "    #     0, 0, 0, 0, 0,  # 4:00 PM to 9:00 PM\n",
    "    #     500, 500, 500  # 9:01 PM to 11:59 PM\n",
    "    # ]\n",
    "\n",
    "    # \"context_prompt\":\n",
    "    # \"From 12:00 AM to 5:00 AM, scheduling soccer practice is unreasonable as it falls outside daylight hours, resulting in a high cost of 500. Between 5:01 AM and 7:00 AM, the early sunrise makes it less ideal, leading to a moderate cost of 100. From 7:01 AM to 4:00 PM, this time is available but not optimal, warranting a low-moderate cost of 50. The period from 4:00 PM to 5:59 PM is ideal for soccer practice, so the cost is 0. From 6:00 PM to 6:59 PM, the yoga class creates a scheduling conflict with an INFINITE cost. Finally, from 7:00 PM to 11:59 PM, scheduling falls outside preferred daylight hours, with a cost ranging linearly from 50 to 100.\"\n",
    "    # \"goal\": \"Generate an array for a 24-hour cost table where each hour reflects its scheduling cost based on the constraints provided.\"\n",
    "    # ”cost_table” : [\n",
    "    #     500, 500, 500, 500, 500,  # 12:00 AM to 5:00 AM\n",
    "    #     100, 100,  # 5:01 AM to 7:00 AM\n",
    "    #     50, 50, 50, 50, 50, 50, 50, 50, 50,  # 7:01 AM to 4:00 PM\n",
    "    #     0, 0,  # 4:00 PM to 5:59 PM\n",
    "    #     float('inf'),  # 6:00 PM to 6:59 PM\n",
    "    #     50, 62, 75, 87, 100  # 7:00 PM to 11:59 PM (linear increase)\n",
    "    # ]\n",
    "\n",
    "\n",
    "\n",
    "    # ]\n",
    "\n",
    "\n",
    "\n",
    "    # \"CONTEXT PROMPT\":\n",
    "    # \"From 12:00 AM to 7:59 AM, these hours are available but less ideal for a doctor's appointment, resulting in a high cost of 200. Between 8:00 AM and 11:59 AM, work constraints render scheduling impossible, with an INFINITE cost. From 12:00 PM to 12:59 PM, this hour is optimal for a doctor's appointment, with a cost of 0. Between 1:00 PM and 4:59 PM, work hours make scheduling unavailable, resulting in an INFINITE cost. From 5:00 PM to 8:59 PM, this period is flexible and available, so the cost is 0. Finally, from 9:00 PM to 11:59 PM, late hours are less ideal for a doctor's appointment, resulting in a high cost of 500.\"\n",
    "    # NEW GOAL: \"Generate an array for a 24-hour cost table where each hour reflects its scheduling cost based on the constraints provided.\"\n",
    "\n",
    "    # \"COST TABLE\" :[\n",
    "\n",
    "\n",
    "\n",
    "    # \"\"\"\n",
    "\n",
    "    # structured_prompt = f\"\"\"\n",
    "\n",
    "    #         Convert the following description to a Python list.\n",
    "    #         Format: [cost at hour 12:00AM-1:00AM, cost at hour 1:01AM-2:00AM, ..., cost at hour 10:01PM-11:00PM, cost at hour 11:01PMM-11:59PM]\n",
    "    #         Rules:\n",
    "    #         - Only return list of numbers\n",
    "    #         - List must have 24 items\n",
    "    #         - Match input constraints exactly\n",
    "\n",
    "\n",
    "    #         New Context Prompt:\n",
    "    #         [{prompt}] -> \n",
    "\n",
    "    #         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from outlines import models, generate\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from enum import Enum\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''\n",
    "\n",
    "\n",
    "# double_quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True)\n",
    "\n",
    "\n",
    "\n",
    "class ForcedGeneration:\n",
    "   \n",
    "    def __init__(self, model):\n",
    "        self.openai = models.openai(\"gpt-4o\", api_key = os.environ[\"OPENAI_API_KEY\"])\n",
    "        # self.llm = models.transformers(model)    \n",
    "        # self.generator = generate.choice(self.llm, [\"500\", \"0\", \"1000\", \"INFINITE\", \"100\"])\n",
    "        self.openaigenerator = generate.choice(self.openai, [\"500\", \"0\", \"1000\", \"INFINITE\", \"100\"])\n",
    "        self.completed_json = {\n",
    "            \"12:00AM-12:59AM\": -1,\n",
    "            \"1:00AM-1:59AM\": -1,\n",
    "            \"2:00AM-2:59AM\": -1,\n",
    "            \"3:00AM-3:59AM\": -1,\n",
    "            \"4:00AM-4:59AM\": -1,\n",
    "            \"5:00AM-5:59AM\": -1,\n",
    "            \"6:00AM-6:59AM\": -1,\n",
    "            \"7:00AM-7:59AM\": -1,\n",
    "            \"8:00AM-8:59AM\": -1,\n",
    "            \"9:00AM-9:59AM\": -1,\n",
    "            \"10:00AM-10:59AM\": -1,\n",
    "            \"11:00AM-11:59AM\": -1,\n",
    "            \"12:00PM-12:59PM\": -1,\n",
    "            \"1:00PM-1:59PM\": -1,\n",
    "            \"2:00PM-2:59PM\": -1,\n",
    "            \"3:00PM-3:59PM\": -1,\n",
    "            \"4:00PM-4:59PM\": -1,\n",
    "            \"5:00PM-5:59PM\": -1,\n",
    "            \"6:00PM-6:59PM\": -1,\n",
    "            \"7:00PM-7:59PM\": -1,\n",
    "            \"8:00PM-8:59PM\": -1,\n",
    "            \"9:00PM-9:59PM\": -1,\n",
    "            \"10:00PM-10:59PM\": -1,\n",
    "            \"11:00PM-11:59PM\": -1\n",
    "        }\n",
    "        print(\"generator loaded\")\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "            # self.target_token_ids = [self.tokenizer.encode(token) for token in self.completed_array]\n",
    "    def gen_context(self, prompt, time):\n",
    "        return f\"\"\"\n",
    "\n",
    "        \n",
    "        You are an intelligent assistant that determines the cost associated with scheduling activities for a specific hour of the day. Your task is to assess the given hour in context and assign a cost from the predefined options: [\"0\", \"100\", \"500\", \"1000\", \"INFINITE\"].\n",
    "\n",
    "        Task Description:\n",
    "        Generate a cost for the specified hour that aligns with natural language constraints and preferences for scheduling activities.\n",
    "\n",
    "        For context:\n",
    "        - Certain times are completely unavailable (e.g., sleep, existing meetings) which have \"INFINITE\" cost.\n",
    "        - Some times are less ideal (e.g., early morning or late evening) which have a cost of \"100\", \"500\", or \"1000\".\n",
    "        - Certain times are optimal for scheduling activities which have a cost of 0.\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        Description:  From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.  \n",
    "        Specified Hour: 1:00AM-1:59AM\n",
    "        Output: \"1000\"  \n",
    "\n",
    "        Description: From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.\n",
    "        Specified Hour: 2:00PM-2:59PM  \n",
    "        Output: \"0\"  \n",
    "\n",
    "        Description: From 12:00 AM to 5:00 AM, scheduling soccer practice is unreasonable as it falls outside daylight hours, resulting in a high cost of 500. Between 5:01 AM and 7:00 AM, the early sunrise makes it less ideal, leading to a moderate cost of 100. From 7:01 AM to 4:00 PM, this time is available but not optimal, warranting a low-moderate cost of 50. The period from 4:00 PM to 5:59 PM is ideal for soccer practice, so the cost is 0. From 6:00 PM to 6:59 PM, the yoga class creates a scheduling conflict with an INFINITE cost. Finally, from 7:00 PM to 11:59 PM, scheduling falls outside preferred daylight hours, with a cost ranging linearly from 50 to 100.  \n",
    "        Specified Hour: 10:00PM-10:59PM  \n",
    "        Output: \"100\"  \n",
    "\n",
    "        Description: From 12:00 AM to 5:00 AM, scheduling soccer practice is unreasonable as it falls outside daylight hours, resulting in a high cost of 500. Between 5:01 AM and 7:00 AM, the early sunrise makes it less ideal, leading to a moderate cost of 100. From 7:01 AM to 4:00 PM, this time is available but not optimal, warranting a low-moderate cost of 50. The period from 4:00 PM to 5:59 PM is ideal for soccer practice, so the cost is 0. From 6:00 PM to 6:59 PM, the yoga class creates a scheduling conflict with an INFINITE cost. Finally, from 7:00 PM to 11:59 PM, scheduling falls outside preferred daylight hours, with a cost ranging linearly from 50 to 100.  \n",
    "        Specified Hour: 7:00AM-7:59PA  \n",
    "        Output: \"100\"  \n",
    "\n",
    "        \n",
    "        Given the following description, determine the cost for the specified hour:\n",
    "\n",
    "        Description: {prompt}  \n",
    "        Specified Hour: {time}\n",
    "\n",
    "        Hard Constraints:\n",
    "        1. Only select a cost from [\"0\", \"100\", \"500\", \"1000\", \"INFINITE\"].\n",
    "        2. Always evaluate and assign a cost based on the specific hour, without inferring across multiple hours.\n",
    "        3. The output should only be the cost value in quotes.\n",
    "        4. If the described cost is not one of the options, return the cost that is closest to the described cost. For example, if the described cost is 50, return \"100\" as 50 is not an option and 100 is the closest option to 50.\n",
    "        5. Do not make up information that is not provided in the description and follow the constraints exactly.\n",
    "\n",
    "        Output:\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    def call(self, prompt):\n",
    "        sentence_so_far = \"\"\n",
    "        keys = list(self.completed_json.keys())\n",
    "\n",
    "        for hour in keys:\n",
    "            # Add the current hour's description to the context\n",
    "            sentence_so_far = self.gen_context(prompt, hour)\n",
    "            gen = None\n",
    "            openai_gen = None\n",
    "            # Use the generator to compute the cost\n",
    "            # try:\n",
    "            #     gen = self.generator(sentence_so_far, max_tokens=3)\n",
    "            #     print(f\"Generated (Transformer): {gen}\")\n",
    "            # except Exception as e:\n",
    "            #     print(f\"Error with Transformer generation: {e}\")\n",
    "            #     gen = \"500\"  # Fallback cost in case of error\n",
    "\n",
    "            try:\n",
    "                #print(\"sentence_so_far: \", sentence_so_far)\n",
    "                openai_gen = self.openaigenerator(sentence_so_far, max_tokens=2500, temperature=0.0)\n",
    "                print(f\"Generated (OpenAI): {openai_gen}\")\n",
    "                cost = openai_gen.strip()\n",
    "            except ValueError:\n",
    "                print(f\"Invalid cost generated by OpenAI: {openai_gen}. Defaulting to Transformer cost.\")\n",
    "                cost = int(gen.strip())\n",
    "            except Exception as e:\n",
    "                print(f\"Error with OpenAI generation: {e}. Defaulting to 500.\")\n",
    "                cost = 500  # Fallback cost in case of error\n",
    "\n",
    "            # Save the generated cost for the current hour\n",
    "            self.completed_json[hour] = cost\n",
    "\n",
    "        # Return the completed JSON as a string\n",
    "        return json.dumps(self.completed_json, indent=4)\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    prompt = \"From 12:00 AM to 7:59 AM, these hours are available but less ideal for a doctor's appointment, resulting in a cost of 200. Between 8:00 AM and 11:59 AM, work constraints render scheduling impossible, with an INFINITE cost. From 12:00 PM to 12:59 PM, this hour is optimal for a doctor's appointment, with a cost of 0. Between 1:00 PM and 4:59 PM, work hours make scheduling unavailable, resulting in an INFINITE cost. From 5:00 PM to 8:59 PM, this period is flexible and available, so the cost is 0. Finally, from 9:00 PM to 11:59 PM, late hours are less ideal for a doctor's appointment, resulting in a high cost of 500.\"\n",
    "    prompt2 =  \"From 12:00 AM to 6:59 AM, sleeping hours make scheduling impossible, resulting in an INFINITE cost. From 7:00 AM to 4:59 PM, these hours are available but less ideal for a date, leading to a moderate cost of 100. Between 5:00 PM and 5:59 PM, this hour is ideal for a date, so the cost is 0. From 6:00 PM to 6:59 PM, the dinner meeting creates a conflict, resulting in an INFINITE cost. Finally, from 7:00 PM to 11:59 PM, these hours are optimal for scheduling a date, with a cost of 0.\"\n",
    "    prompt3 = \"From 12:00 AM to 7:59 AM, scheduling is not possible, as activities cannot be scheduled during these hours, resulting in an INFINITE cost. From 8:00 AM to 9:59 AM, this time is available but not ideal for lunch meetings, warranting a moderate cost of 50. From 10:00 AM to 10:59 AM, the team meeting makes scheduling impossible, with an INFINITE cost. Between 11:00 AM and 12:59 PM, this period is optimal for lunch meetings, so the cost is 0. From 1:00 PM to 1:59 PM, late lunch scheduling is less preferable, resulting in a high cost of 100. Finally, from 2:00 PM to 11:59 PM, scheduling a lunch meeting is unsuitable, with an INFINITE cost.\"\n",
    "    model = \"HuggingFaceH4/zephyr-7b-alpha\"\n",
    "    # model = \"facebook/opt-iml-max-1.3b\"\n",
    "    gen = ForcedGeneration(model)\n",
    "    result = gen.call(prompt2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator loaded\n",
      "Generated (OpenAI): INFINITE\n",
      "Generated (OpenAI): INFINITE\n",
      "Generated (OpenAI): INFINITE\n",
      "Generated (OpenAI): INFINITE\n",
      "Generated (OpenAI): INFINITE\n",
      "Generated (OpenAI): INFINITE\n",
      "Generated (OpenAI): INFINITE\n",
      "Generated (OpenAI): 100\n",
      "Generated (OpenAI): 100\n",
      "Generated (OpenAI): 100\n",
      "Generated (OpenAI): 100\n",
      "Generated (OpenAI): 100\n",
      "Generated (OpenAI): 100\n",
      "Generated (OpenAI): 100\n",
      "Generated (OpenAI): 100\n",
      "Generated (OpenAI): 100\n",
      "Generated (OpenAI): 100\n",
      "Generated (OpenAI): 0\n",
      "Generated (OpenAI): INFINITE\n",
      "Generated (OpenAI): 0\n",
      "Generated (OpenAI): 0\n",
      "Generated (OpenAI): 0\n",
      "Generated (OpenAI): 0\n",
      "Generated (OpenAI): 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n    \"12:00AM-12:59AM\": \"INFINITE\",\\n    \"1:00AM-1:59AM\": \"INFINITE\",\\n    \"2:00AM-2:59AM\": \"INFINITE\",\\n    \"3:00AM-3:59AM\": \"INFINITE\",\\n    \"4:00AM-4:59AM\": \"INFINITE\",\\n    \"5:00AM-5:59AM\": \"INFINITE\",\\n    \"6:00AM-6:59AM\": \"INFINITE\",\\n    \"7:00AM-7:59AM\": \"100\",\\n    \"8:00AM-8:59AM\": \"100\",\\n    \"9:00AM-9:59AM\": \"100\",\\n    \"10:00AM-10:59AM\": \"100\",\\n    \"11:00AM-11:59AM\": \"100\",\\n    \"12:00PM-12:59PM\": \"100\",\\n    \"1:00PM-1:59PM\": \"100\",\\n    \"2:00PM-2:59PM\": \"100\",\\n    \"3:00PM-3:59PM\": \"100\",\\n    \"4:00PM-4:59PM\": \"100\",\\n    \"5:00PM-5:59PM\": \"0\",\\n    \"6:00PM-6:59PM\": \"INFINITE\",\\n    \"7:00PM-7:59PM\": \"0\",\\n    \"8:00PM-8:59PM\": \"0\",\\n    \"9:00PM-9:59PM\": \"0\",\\n    \"10:00PM-10:59PM\": \"0\",\\n    \"11:00PM-11:59PM\": \"0\"\\n}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting outlines\n",
      "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.45.0-py3-none-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting interegular (from outlines)\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jinja2 (from outlines)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting lark (from outlines)\n",
      "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nest_asyncio (from outlines)\n",
      "  Using cached nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy (from outlines)\n",
      "  Using cached numpy-2.2.0-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting cloudpickle (from outlines)\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting diskcache (from outlines)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting pydantic>=2.0 (from outlines)\n",
      "  Using cached pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "Collecting referencing (from outlines)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting jsonschema (from outlines)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting requests (from outlines)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from outlines)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing_extensions (from outlines)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pycountry (from outlines)\n",
      "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting airportsdata (from outlines)\n",
      "  Using cached airportsdata-20241001-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting torch (from outlines)\n",
      "  Using cached torch-2.5.1-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting outlines_core==0.1.26 (from outlines)\n",
      "  Downloading outlines_core-0.1.26-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-18.1.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.11.10-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Using cached propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->outlines)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic>=2.0->outlines)\n",
      "  Using cached pydantic_core-2.27.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->outlines)\n",
      "  Using cached charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->outlines)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->outlines)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->outlines)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting colorama (from tqdm->outlines)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->outlines)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->outlines)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->outlines)\n",
      "  Using cached rpds_py-0.22.3-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->datasets)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting networkx (from torch->outlines)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch->outlines)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->outlines)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Downloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.6/87.6 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading outlines_core-0.1.26-cp311-cp311-win_amd64.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.5 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 122.9/243.5 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 243.5/243.5 kB 3.0 MB/s eta 0:00:00\n",
      "Using cached transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached bitsandbytes-0.45.0-py3-none-win_amd64.whl (68.5 MB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached aiohttp-3.11.10-cp311-cp311-win_amd64.whl (442 kB)\n",
      "Using cached huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached numpy-2.2.0-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pyarrow-18.1.0-cp311-cp311-win_amd64.whl (25.1 MB)\n",
      "Using cached pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "Using cached pydantic_core-2.27.1-cp311-none-win_amd64.whl (2.0 MB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached airportsdata-20241001-py3-none-any.whl (912 kB)\n",
      "Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "Using cached torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl (101 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Using cached propcache-0.2.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached rpds_py-0.22.3-cp311-cp311-win_amd64.whl (231 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, mpmath, xxhash, urllib3, tzdata, typing_extensions, sympy, six, safetensors, rpds-py, regex, pyyaml, pycountry, pyarrow, propcache, packaging, numpy, networkx, nest_asyncio, multidict, MarkupSafe, lark, interegular, idna, fsspec, frozenlist, filelock, diskcache, dill, colorama, cloudpickle, charset-normalizer, certifi, attrs, annotated-types, airportsdata, aiohappyeyeballs, yarl, tqdm, requests, referencing, python-dateutil, pydantic-core, multiprocess, jinja2, aiosignal, torch, pydantic, pandas, jsonschema-specifications, huggingface-hub, aiohttp, tokenizers, jsonschema, bitsandbytes, transformers, outlines_core, datasets, outlines\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.2\n",
      "    Uninstalling pytz-2024.2:\n",
      "      Successfully uninstalled pytz-2024.2\n",
      "  Attempting uninstall: mpmath\n",
      "    Found existing installation: mpmath 1.3.0\n",
      "    Uninstalling mpmath-1.3.0:\n",
      "      Successfully uninstalled mpmath-1.3.0\n",
      "  Attempting uninstall: xxhash\n",
      "    Found existing installation: xxhash 3.5.0\n",
      "    Uninstalling xxhash-3.5.0:\n",
      "      Successfully uninstalled xxhash-3.5.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2024.2\n",
      "    Uninstalling tzdata-2024.2:\n",
      "      Successfully uninstalled tzdata-2024.2\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.4.5\n",
      "    Uninstalling safetensors-0.4.5:\n",
      "      Successfully uninstalled safetensors-0.4.5\n",
      "  Attempting uninstall: rpds-py\n",
      "    Found existing installation: rpds-py 0.22.3\n",
      "    Uninstalling rpds-py-0.22.3:\n",
      "      Successfully uninstalled rpds-py-0.22.3\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.11.6\n",
      "    Uninstalling regex-2024.11.6:\n",
      "      Successfully uninstalled regex-2024.11.6\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: pycountry\n",
      "    Found existing installation: pycountry 24.6.1\n",
      "    Uninstalling pycountry-24.6.1:\n",
      "      Successfully uninstalled pycountry-24.6.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: propcache\n",
      "    Found existing installation: propcache 0.2.1\n",
      "    Uninstalling propcache-0.2.1:\n",
      "      Successfully uninstalled propcache-0.2.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.0\n",
      "    Uninstalling numpy-2.2.0:\n",
      "      Successfully uninstalled numpy-2.2.0\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.4.2\n",
      "    Uninstalling networkx-3.4.2:\n",
      "      Successfully uninstalled networkx-3.4.2\n",
      "  Attempting uninstall: nest_asyncio\n",
      "    Found existing installation: nest-asyncio 1.6.0\n",
      "    Uninstalling nest-asyncio-1.6.0:\n",
      "      Successfully uninstalled nest-asyncio-1.6.0\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.1.0\n",
      "    Uninstalling multidict-6.1.0:\n",
      "      Successfully uninstalled multidict-6.1.0\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: lark\n",
      "    Found existing installation: lark 1.2.2\n",
      "    Uninstalling lark-1.2.2:\n",
      "      Successfully uninstalled lark-1.2.2\n",
      "  Attempting uninstall: interegular\n",
      "    Found existing installation: interegular 0.3.3\n",
      "    Uninstalling interegular-0.3.3:\n",
      "      Successfully uninstalled interegular-0.3.3\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.5.0\n",
      "    Uninstalling frozenlist-1.5.0:\n",
      "      Successfully uninstalled frozenlist-1.5.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.16.1\n",
      "    Uninstalling filelock-3.16.1:\n",
      "      Successfully uninstalled filelock-3.16.1\n",
      "  Attempting uninstall: diskcache\n",
      "    Found existing installation: diskcache 5.6.3\n",
      "    Uninstalling diskcache-5.6.3:\n",
      "      Successfully uninstalled diskcache-5.6.3\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 3.1.0\n",
      "    Uninstalling cloudpickle-3.1.0:\n",
      "      Successfully uninstalled cloudpickle-3.1.0\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.0\n",
      "    Uninstalling charset-normalizer-3.4.0:\n",
      "      Successfully uninstalled charset-normalizer-3.4.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.8.30\n",
      "    Uninstalling certifi-2024.8.30:\n",
      "      Successfully uninstalled certifi-2024.8.30\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 24.2.0\n",
      "    Uninstalling attrs-24.2.0:\n",
      "      Successfully uninstalled attrs-24.2.0\n",
      "  Attempting uninstall: annotated-types\n",
      "    Found existing installation: annotated-types 0.7.0\n",
      "    Uninstalling annotated-types-0.7.0:\n",
      "      Successfully uninstalled annotated-types-0.7.0\n",
      "  Attempting uninstall: airportsdata\n",
      "    Found existing installation: airportsdata 20241001\n",
      "    Uninstalling airportsdata-20241001:\n",
      "      Successfully uninstalled airportsdata-20241001\n",
      "  Attempting uninstall: aiohappyeyeballs\n",
      "    Found existing installation: aiohappyeyeballs 2.4.4\n",
      "    Uninstalling aiohappyeyeballs-2.4.4:\n",
      "      Successfully uninstalled aiohappyeyeballs-2.4.4\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.18.3\n",
      "    Uninstalling yarl-1.18.3:\n",
      "      Successfully uninstalled yarl-1.18.3\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: referencing\n",
      "    Found existing installation: referencing 0.35.1\n",
      "    Uninstalling referencing-0.35.1:\n",
      "      Successfully uninstalled referencing-0.35.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.1\n",
      "    Uninstalling pydantic_core-2.27.1:\n",
      "      Successfully uninstalled pydantic_core-2.27.1\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.4\n",
      "    Uninstalling Jinja2-3.1.4:\n",
      "      Successfully uninstalled Jinja2-3.1.4\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.3.1\n",
      "    Uninstalling aiosignal-1.3.1:\n",
      "      Successfully uninstalled aiosignal-1.3.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.3\n",
      "    Uninstalling pydantic-2.10.3:\n",
      "      Successfully uninstalled pydantic-2.10.3\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "  Attempting uninstall: jsonschema-specifications\n",
      "    Found existing installation: jsonschema-specifications 2024.10.1\n",
      "    Uninstalling jsonschema-specifications-2024.10.1:\n",
      "      Successfully uninstalled jsonschema-specifications-2024.10.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.26.5\n",
      "    Uninstalling huggingface-hub-0.26.5:\n",
      "      Successfully uninstalled huggingface-hub-0.26.5\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.11.10\n",
      "    Uninstalling aiohttp-3.11.10:\n",
      "      Successfully uninstalled aiohttp-3.11.10\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.23.0\n",
      "    Uninstalling jsonschema-4.23.0:\n",
      "      Successfully uninstalled jsonschema-4.23.0\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.45.0\n",
      "    Uninstalling bitsandbytes-0.45.0:\n",
      "      Successfully uninstalled bitsandbytes-0.45.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.47.0\n",
      "    Uninstalling transformers-4.47.0:\n",
      "      Successfully uninstalled transformers-4.47.0\n",
      "  Attempting uninstall: outlines_core\n",
      "    Found existing installation: outlines_core 0.1.25\n",
      "    Uninstalling outlines_core-0.1.25:\n",
      "      Successfully uninstalled outlines_core-0.1.25\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.2.0\n",
      "    Uninstalling datasets-3.2.0:\n",
      "      Successfully uninstalled datasets-3.2.0\n",
      "  Attempting uninstall: outlines\n",
      "    Found existing installation: outlines 0.1.10\n",
      "    Uninstalling outlines-0.1.10:\n",
      "      Successfully uninstalled outlines-0.1.10\n",
      "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.2 airportsdata-20241001 annotated-types-0.7.0 attrs-24.2.0 bitsandbytes-0.45.0 certifi-2024.8.30 charset-normalizer-3.4.0 cloudpickle-3.1.0 colorama-0.4.6 datasets-3.2.0 dill-0.3.8 diskcache-5.6.3 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.5 idna-3.10 interegular-0.3.3 jinja2-3.1.4 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 lark-1.2.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 nest_asyncio-1.6.0 networkx-3.4.2 numpy-2.2.0 outlines-0.1.11 outlines_core-0.1.26 packaging-24.2 pandas-2.2.3 propcache-0.2.1 pyarrow-18.1.0 pycountry-24.6.1 pydantic-2.10.3 pydantic-core-2.27.1 python-dateutil-2.9.0.post0 pytz-2024.2 pyyaml-6.0.2 referencing-0.35.1 regex-2024.11.6 requests-2.32.3 rpds-py-0.22.3 safetensors-0.4.5 six-1.17.0 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 tqdm-4.67.1 transformers-4.47.0 typing_extensions-4.12.2 tzdata-2024.2 urllib3-2.2.3 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~-fetensors'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~-gex'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~-ml'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~-rkupsafe'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~harset_normalizer'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~-dantic_core'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~-rch'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~-kenizers'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~-tlines_core'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "scikit-image 0.23.1 requires imageio>=2.33, but you have imageio 2.26.0 which is incompatible.\n",
      "scikit-image 0.23.1 requires lazy-loader>=0.4, but you have lazy-loader 0.2 which is incompatible.\n",
      "scikit-image 0.23.1 requires tifffile>=2022.8.12, but you have tifffile 2021.7.2 which is incompatible.\n",
      "botocore 1.27.59 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.3 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires python-dateutil==2.8.2, but you have python-dateutil 2.9.0.post0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires PyYAML==6.0, but you have pyyaml 6.0.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.32.3 which is incompatible.\n",
      "numba 0.57.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.0 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "s3fs 2023.3.0 requires fsspec==2023.3.0, but you have fsspec 2024.9.0 which is incompatible.\n",
      "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.2.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall outlines transformers datasets bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\dorian\\anaconda3\\lib\\site-packages (1.57.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\dorian\\anaconda3\\lib\\site-packages (1.2.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (0.26.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-gptq\n",
      "  Obtaining dependency information for auto-gptq from https://files.pythonhosted.org/packages/e2/8e/6c90faf9c4058215341523c1fd0e70ac49c504023af2fcd0bd89a825dd72/auto_gptq-0.7.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading auto_gptq-0.7.1-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
      "Collecting optimum\n",
      "  Obtaining dependency information for optimum from https://files.pythonhosted.org/packages/48/33/97cf226c47e4cf5a79159668732038cdd6c0199c72782d5b5a0db54f9a2d/optimum-1.23.3-py3-none-any.whl.metadata\n",
      "  Downloading optimum-1.23.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from auto-gptq) (1.2.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from auto-gptq) (3.1.0)\n",
      "Collecting sentencepiece (from auto-gptq)\n",
      "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/a2/f6/587c62fd21fc988555b85351f50bbde43a51524caafd63bc69240ded14fd/sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from auto-gptq) (2.1.1)\n",
      "Collecting rouge (from auto-gptq)\n",
      "  Obtaining dependency information for rouge from https://files.pythonhosted.org/packages/32/7c/650ae86f92460e9e8ef969cc5008b24798dcf56a9a8947d04c78f550b3f5/rouge-1.0.1-py3-none-any.whl.metadata\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting gekko (from auto-gptq)\n",
      "  Obtaining dependency information for gekko from https://files.pythonhosted.org/packages/47/45/e48a94be1b31b0354aa453b0c2474d4ceb4b45653066d1d94085ae45605b/gekko-1.2.1-py3-none-any.whl.metadata\n",
      "  Downloading gekko-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from auto-gptq) (2.5.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from auto-gptq) (0.4.5)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from auto-gptq) (4.47.0)\n",
      "Collecting peft>=0.5.0 (from auto-gptq)\n",
      "  Obtaining dependency information for peft>=0.5.0 from https://files.pythonhosted.org/packages/88/05/e58e3aaa36544d30a917814e336fc65a746f708e5874945e92999bc22fa3/peft-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from auto-gptq) (4.66.5)\n",
      "Collecting coloredlogs (from optimum)\n",
      "  Obtaining dependency information for coloredlogs from https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from optimum) (1.13.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from optimum) (24.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from optimum) (0.26.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from accelerate>=0.26.0->auto-gptq) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from accelerate>=0.26.0->auto-gptq) (6.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (2024.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from torch>=1.13.0->auto-gptq) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from torch>=1.13.0->auto-gptq) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from tqdm->auto-gptq) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from transformers>=4.31.0->auto-gptq) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from transformers>=4.31.0->auto-gptq) (0.21.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\n",
      "  Obtaining dependency information for humanfriendly>=9.1 from https://files.pythonhosted.org/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from datasets->auto-gptq) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from datasets->auto-gptq) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from datasets->auto-gptq) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from datasets->auto-gptq) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from datasets->auto-gptq) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from datasets->auto-gptq) (3.11.10)\n",
      "Requirement already satisfied: six in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from rouge->auto-gptq) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (1.18.3)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->optimum)\n",
      "  Obtaining dependency information for pyreadline3 from https://files.pythonhosted.org/packages/5a/dc/491b7661614ab97483abf2056be1deee4dc2490ecbf7bff9ab5cdbac86e1/pyreadline3-3.5.4-py3-none-any.whl.metadata\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from jinja2->torch>=1.13.0->auto-gptq) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from pandas->datasets->auto-gptq) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from pandas->datasets->auto-gptq) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dorian\\documents\\rbr\\venv\\lib\\site-packages (from pandas->datasets->auto-gptq) (2024.2)\n",
      "Downloading auto_gptq-0.7.1-cp311-cp311-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.6 MB 435.7 kB/s eta 0:00:11\n",
      "   ---------------------------------------- 0.0/4.6 MB 435.7 kB/s eta 0:00:11\n",
      "    --------------------------------------- 0.1/4.6 MB 491.5 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.1/4.6 MB 491.5 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.1/4.6 MB 403.5 kB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.1/4.6 MB 500.5 kB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.1/4.6 MB 500.5 kB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.2/4.6 MB 409.6 kB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.2/4.6 MB 436.9 kB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.2/4.6 MB 474.7 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.2/4.6 MB 480.3 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.2/4.6 MB 480.3 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.2/4.6 MB 480.3 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.3/4.6 MB 475.1 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.3/4.6 MB 475.1 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.3/4.6 MB 475.1 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.4/4.6 MB 467.9 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.4/4.6 MB 467.9 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.4/4.6 MB 500.7 kB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.4/4.6 MB 500.7 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.5/4.6 MB 507.2 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.5/4.6 MB 507.2 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.6/4.6 MB 528.1 kB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 0.6/4.6 MB 528.1 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.6/4.6 MB 549.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.6/4.6 MB 549.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.7/4.6 MB 554.4 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.7/4.6 MB 554.4 kB/s eta 0:00:08\n",
      "   ------ --------------------------------- 0.7/4.6 MB 555.2 kB/s eta 0:00:08\n",
      "   ------ --------------------------------- 0.8/4.6 MB 552.1 kB/s eta 0:00:08\n",
      "   ------ --------------------------------- 0.8/4.6 MB 568.1 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.8/4.6 MB 565.8 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.9/4.6 MB 587.1 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 0.9/4.6 MB 590.5 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 0.9/4.6 MB 590.5 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.0/4.6 MB 624.5 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 1.1/4.6 MB 637.8 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 1.2/4.6 MB 661.4 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 1.2/4.6 MB 661.4 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 1.2/4.6 MB 666.6 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 1.2/4.6 MB 644.7 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 1.3/4.6 MB 686.9 kB/s eta 0:00:05\n",
      "   ------------ --------------------------- 1.4/4.6 MB 696.3 kB/s eta 0:00:05\n",
      "   ------------ --------------------------- 1.4/4.6 MB 696.3 kB/s eta 0:00:05\n",
      "   ------------ --------------------------- 1.5/4.6 MB 714.0 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 1.5/4.6 MB 713.7 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 1.6/4.6 MB 726.0 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 1.7/4.6 MB 756.3 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 1.7/4.6 MB 760.0 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 1.8/4.6 MB 787.4 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 1.9/4.6 MB 798.7 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 2.0/4.6 MB 820.2 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 2.1/4.6 MB 837.8 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 2.2/4.6 MB 866.9 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 2.3/4.6 MB 875.0 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 2.3/4.6 MB 885.8 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 2.4/4.6 MB 911.2 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.5/4.6 MB 928.2 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.5/4.6 MB 934.0 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 2.7/4.6 MB 962.9 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 2.7/4.6 MB 957.7 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.8/4.6 MB 981.1 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.9/4.6 MB 975.9 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.0/4.6 MB 998.6 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.1/4.6 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.1/4.6 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 3.3/4.6 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 3.3/4.6 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 3.4/4.6 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 3.5/4.6 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 3.6/4.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.7/4.6 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.8/4.6 MB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.9/4.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.0/4.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.1/4.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.2/4.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.3/4.6 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.5/4.6 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.5/4.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.6/4.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.6/4.6 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading optimum-1.23.3-py3-none-any.whl (424 kB)\n",
      "   ---------------------------------------- 0.0/424.1 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 81.9/424.1 kB 4.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 194.6/424.1 kB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 327.7/424.1 kB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 337.9/424.1 kB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 409.6/424.1 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 424.1/424.1 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "   ---------------------------------------- 0.0/374.8 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 102.4/374.8 kB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 235.5/374.8 kB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 297.0/374.8 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  368.6/374.8 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 374.8/374.8 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading gekko-1.2.1-py3-none-any.whl (13.2 MB)\n",
      "   ---------------------------------------- 0.0/13.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/13.2 MB 1.5 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.2/13.2 MB 2.8 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.3/13.2 MB 2.4 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.4/13.2 MB 2.2 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/13.2 MB 2.4 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/13.2 MB 1.7 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.7/13.2 MB 2.0 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.8/13.2 MB 2.2 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.8/13.2 MB 2.2 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.8/13.2 MB 1.9 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.9/13.2 MB 1.8 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.0/13.2 MB 1.7 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.1/13.2 MB 1.7 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.2/13.2 MB 1.8 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.3/13.2 MB 1.8 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.4/13.2 MB 1.9 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.6/13.2 MB 2.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.7/13.2 MB 2.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.8/13.2 MB 2.0 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.0/13.2 MB 2.1 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.1/13.2 MB 2.1 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.3/13.2 MB 2.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.3/13.2 MB 2.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.5/13.2 MB 2.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.6/13.2 MB 2.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.7/13.2 MB 2.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.9/13.2 MB 2.3 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.0/13.2 MB 2.3 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.2/13.2 MB 2.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.3/13.2 MB 2.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.5/13.2 MB 2.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.7/13.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.7/13.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.8/13.2 MB 2.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.9/13.2 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.1/13.2 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.1/13.2 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.3/13.2 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.5/13.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.5/13.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.6/13.2 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.7/13.2 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.9/13.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.9/13.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.0/13.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.0/13.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.0/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.2/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.2/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.4/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.5/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.6/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.7/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.9/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.9/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.9/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.9/13.2 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 6.1/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.3/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.3/13.2 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.5/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.7/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.7/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.9/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.0/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.1/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.1/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.3/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.5/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.5/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.6/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.8/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.8/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.0/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.2/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.2/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.3/13.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.5/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.6/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.7/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.9/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.0/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.1/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.3/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.4/13.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.4/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.5/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.7/13.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.7/13.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.9/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.9/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.0/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.1/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.2/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.4/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.5/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.5/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.5/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 10.6/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 10.7/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 10.8/13.2 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.9/13.2 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.9/13.2 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.9/13.2 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.0/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.1/13.2 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.2/13.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.3/13.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.3/13.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.3/13.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.4/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.7/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.7/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.7/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.8/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.0/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.1/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.1/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.1/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.2/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.4/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.5/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.5/13.2 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.6/13.2 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.7/13.2 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.8/13.2 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.8/13.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.9/13.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.0/13.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.1/13.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.1/13.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.2/13.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.2/13.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.2/13.2 MB 2.0 MB/s eta 0:00:00\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 92.2/991.5 kB 5.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 256.0/991.5 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 409.6/991.5 kB 3.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 532.5/991.5 kB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 634.9/991.5 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 849.9/991.5 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  983.0/991.5 kB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  983.0/991.5 kB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 81.9/86.8 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 86.8/86.8 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "   ---------------------------------------- 0.0/83.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 83.2/83.2 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece, rouge, pyreadline3, gekko, humanfriendly, coloredlogs, peft, optimum, auto-gptq\n",
      "Successfully installed auto-gptq-0.7.1 coloredlogs-15.0.1 gekko-1.2.1 humanfriendly-10.0 optimum-1.23.3 peft-0.14.0 pyreadline3-3.5.4 rouge-1.0.1 sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install auto-gptq optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from outlines import models, generate\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from auto_gptq import AutoGPTQForCausalLM\n",
    "import torch\n",
    "\n",
    "class model_class:\n",
    "    def __init__(self, model_name):\n",
    "        # Load quantized model using GPTQ\n",
    "        model = AutoGPTQForCausalLM.from_quantized(\n",
    "            model_name,\n",
    "            #model_basename=\"gptq_model-4bit-128g\",\n",
    "            use_safetensors=True,\n",
    "            trust_remote_code=True,\n",
    "            device=\"cpu\",\n",
    "            use_triton=False,  # Triton is GPU-only, disable for CPU\n",
    "            # quantize_config={\n",
    "            # \"bits\": 4,  # Use 4-bit quantization\n",
    "            # \"group_size\": 128,\n",
    "            # \"desc_act\": True,\n",
    "            # }\n",
    "        )\n",
    "        \n",
    "        self.model = model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "class ForcedGeneration:\n",
    "    def __init__(self, model_name):\n",
    "        self.openai = models.openai(\"gpt-4o\", api_key =\"\")\n",
    "        model = model_class(model_name)\n",
    "        self.llm = models.transformers(model)    \n",
    "        self.generator = generate.choice(self.llm, [\"500\", \"0\", \"1000\", \"INFINITE\", \"100\"])\n",
    "        self.openaigenerator = generate.choice(self.openai, [\"500\", \"0\", \"1000\", \"INFINITE\", \"100\"])\n",
    "        self.completed_json = {\n",
    "            \"12:00AM-12:59AM\": -1,\n",
    "            \"1:00AM-1:59AM\": -1,\n",
    "            \"2:00AM-2:59AM\": -1,\n",
    "            \"3:00AM-3:59AM\": -1,\n",
    "            \"4:00AM-4:59AM\": -1,\n",
    "            \"5:00AM-5:59AM\": -1,\n",
    "            \"6:00AM-6:59AM\": -1,\n",
    "            \"7:00AM-7:59AM\": -1,\n",
    "            \"8:00AM-8:59AM\": -1,\n",
    "            \"9:00AM-9:59AM\": -1,\n",
    "            \"10:00AM-10:59AM\": -1,\n",
    "            \"11:00AM-11:59AM\": -1,\n",
    "            \"12:00PM-12:59PM\": -1,\n",
    "            \"1:00PM-1:59PM\": -1,\n",
    "            \"2:00PM-2:59PM\": -1,\n",
    "            \"3:00PM-3:59PM\": -1,\n",
    "            \"4:00PM-4:59PM\": -1,\n",
    "            \"5:00PM-5:59PM\": -1,\n",
    "            \"6:00PM-6:59PM\": -1,\n",
    "            \"7:00PM-7:59PM\": -1,\n",
    "            \"8:00PM-8:59PM\": -1,\n",
    "            \"9:00PM-9:59PM\": -1,\n",
    "            \"10:00PM-10:59PM\": -1,\n",
    "            \"11:00PM-11:59PM\": -1\n",
    "        }\n",
    "        print(\"generator loaded\")\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "            # self.target_token_ids = [self.tokenizer.encode(token) for token in self.completed_array]\n",
    "    def gen_context(self, prompt, time):\n",
    "        return \"\"\"\n",
    "\n",
    "        \n",
    "        You are an intelligent assistant that determines the cost associated with scheduling activities for a specific hour of the day. Your task is to assess the given hour in context and assign a cost from the predefined options: [\"0\", \"100\", \"500\", \"1000\", \"INFINITE\"].\n",
    "\n",
    "        Task Description:\n",
    "        Generate 24-hour cost table that aligns with natural language constraints and preferences for scheduling activities.\n",
    "\n",
    "        - Certain times are completely unavailable (e.g., sleep, existing meetings) which should have \"INFINITE\" cost.\n",
    "        - Some times are less ideal (e.g., early morning or late evening) which should have a cost of \"100\", \"500\", or \"1000\".\n",
    "        - Certain times are optimal for scheduling activities which should have a cost of 0.\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        Description:  From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.  \n",
    "        Specified Hour: 1:00AM-1:59AM\n",
    "        Output: \"1000\"  \n",
    "\n",
    "        Description: From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.\n",
    "        Specified Hour: 2:00PM-2:59PM  \n",
    "        Output: \"0\"  \n",
    "\n",
    "        Description: From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.  \n",
    "        Specified Hour: 10:00PM-10:59PM  \n",
    "        Output: \"500\"  \n",
    "\n",
    "\n",
    "        \n",
    "        Given the following description, determine the cost for the specified hour:\n",
    "\n",
    "        Description: {prompt}  \n",
    "        Specified Hour: {time}  \n",
    "\n",
    "        # Hard Constraints:\n",
    "        1. Only select a cost from [\"0\", \"100\", \"500\", \"1000\", \"INFINITE\"].\n",
    "        2. Always evaluate and assign a cost based on the specific hour, without inferring across multiple hours.\n",
    "        3. The output should only be the cost value in quotes.\n",
    "\n",
    "        Output:\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    def call(self, prompt):\n",
    "        sentence_so_far = \"\"\n",
    "        keys = list(self.completed_json.keys())\n",
    "\n",
    "        for hour in keys:\n",
    "            # Add the current hour's description to the context\n",
    "            sentence_so_far = self.gen_context(prompt, hour)\n",
    "            gen = None\n",
    "            openai_gen = None\n",
    "            # Use the generator to compute the cost\n",
    "            try:\n",
    "                gen = self.generator(sentence_so_far, max_tokens=3)\n",
    "                print(f\"Generated (Transformer): {gen}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error with Transformer generation: {e}\")\n",
    "                gen = \"500\"  # Fallback cost in case of error\n",
    "\n",
    "            try:\n",
    "                openai_gen = self.openaigenerator(sentence_so_far, max_tokens=3)\n",
    "                print(f\"Generated (OpenAI): {openai_gen}\")\n",
    "                cost = int(openai_gen.strip())\n",
    "            except ValueError:\n",
    "                print(f\"Invalid cost generated by OpenAI: {openai_gen}. Defaulting to Transformer cost.\")\n",
    "                cost = int(gen.strip())\n",
    "            except Exception as e:\n",
    "                print(f\"Error with OpenAI generation: {e}. Defaulting to 500.\")\n",
    "                cost = 500  # Fallback cost in case of error\n",
    "\n",
    "            # Save the generated cost for the current hour\n",
    "            self.completed_json[hour] = gen\n",
    "\n",
    "        # Return the completed JSON as a string\n",
    "        return json.dumps(self.completed_json, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    prompt = prompt = \"From 12:00 AM to 7:59 AM, these hours are available but less ideal for a doctor's appointment, resulting in a high cost of 200. Between 8:00 AM and 11:59 AM, work constraints render scheduling impossible, with an INFINITE cost. From 12:00 PM to 12:59 PM, this hour is optimal for a doctor's appointment, with a cost of 0. Between 1:00 PM and 4:59 PM, work hours make scheduling unavailable, resulting in an INFINITE cost. From 5:00 PM to 8:59 PM, this period is flexible and available, so the cost is 0. Finally, from 9:00 PM to 11:59 PM, late hours are less ideal for a doctor's appointment, resulting in a high cost of 500.\"\n",
    "    # Use a pre-quantized model\n",
    "    model = \"TheBloke/Llama-2-7B-32K-Instruct-GPTQ\"  # Example of a GPTQ quantized model\n",
    "    gen = ForcedGeneration(model)\n",
    "    result = gen.call(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Exllamav2 kernel is not installed, reset disable_exllamav2 to True. This may because you installed auto_gptq using a pre-build wheel on Windows, in which exllama_kernels are not compiled. To use exllama_kernels to further speedup inference, you can re-install auto_gptq from source.\n",
      "WARNING - CUDA kernels for auto_gptq are not installed, this will result in very slow inference speed. This may because:\n",
      "1. You disabled CUDA extensions compilation by setting BUILD_CUDA_EXT=0 when install auto_gptq from source.\n",
      "2. You are using pytorch without CUDA support.\n",
      "3. CUDA and nvcc are not installed in your device.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Please install Flash Attention: `pip install flash-attn --no-build-isolation`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\togethercomputer\\LLaMA-2-7B-32K\\46c24bb5aef59722fa7aa6d75e832afd1d64b980\\modeling_flash_llama.py:38\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflash_attn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflash_attn_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m         flash_attn_func, \n\u001b[0;32m     40\u001b[0m         flash_attn_kvpacked_func, \n\u001b[0;32m     41\u001b[0m         flash_attn_qkvpacked_func,\n\u001b[0;32m     42\u001b[0m         flash_attn_varlen_kvpacked_func, \n\u001b[0;32m     43\u001b[0m     )\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflash_attn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbert_padding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unpad_input, pad_input\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'flash_attn'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis worked?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[36], line 5\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Use a pre-quantized model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTheBloke/Llama-2-7B-32K-Instruct-GPTQ\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Example of a GPTQ quantized model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[43mForcedGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m result \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39mcall(prompt)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[35], line 33\u001b[0m, in \u001b[0;36mForcedGeneration.__init__\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mopenai(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_key \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mtransformers(model)    \n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator \u001b[38;5;241m=\u001b[39m generate\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m500\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFINITE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[35], line 11\u001b[0m, in \u001b[0;36mmodel_class.__init__\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Load quantized model using GPTQ\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoGPTQForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_quantized\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#model_basename=\"gptq_model-4bit-128g\",\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_triton\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Triton is GPU-only, disable for CPU\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# quantize_config={\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"bits\": 4,  # Use 4-bit quantization\u001b[39;49;00m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"group_size\": 128,\u001b[39;49;00m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"desc_act\": True,\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# }\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m     26\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\auto_gptq\\modeling\\auto.py:135\u001b[0m, in \u001b[0;36mAutoGPTQForCausalLM.from_quantized\u001b[1;34m(cls, model_name_or_path, device_map, max_memory, device, low_cpu_mem_usage, use_triton, inject_fused_attention, inject_fused_mlp, use_cuda_fp16, quantize_config, model_basename, use_safetensors, trust_remote_code, warmup_triton, trainable, disable_exllama, disable_exllamav2, use_marlin, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# TODO: do we need this filtering of kwargs? @PanQiWei is there a reason we can't just pass all kwargs?\u001b[39;00m\n\u001b[0;32m    130\u001b[0m keywords \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    131\u001b[0m     key: kwargs[key]\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(signature(quant_func)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m+\u001b[39m huggingface_kwargs\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[0;32m    134\u001b[0m }\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquant_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_triton\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_triton\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43minject_fused_attention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minject_fused_attention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43minject_fused_mlp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minject_fused_mlp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cuda_fp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cuda_fp16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantize_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantize_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_basename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_basename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_triton\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_triton\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_exllama\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_exllama\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_exllamav2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_exllamav2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_marlin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_marlin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\auto_gptq\\modeling\\_base.py:999\u001b[0m, in \u001b[0;36mBaseGPTQForCausalLM.from_quantized\u001b[1;34m(cls, model_name_or_path, device_map, max_memory, device, low_cpu_mem_usage, use_triton, use_qigen, use_marlin, torch_dtype, inject_fused_attention, inject_fused_mlp, use_cuda_fp16, quantize_config, model_basename, use_safetensors, trust_remote_code, warmup_triton, trainable, disable_exllama, disable_exllamav2, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m     init_contexts\u001b[38;5;241m.\u001b[39mappend(accelerate\u001b[38;5;241m.\u001b[39minit_empty_weights(include_buffers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m--> 999\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1003\u001b[0m     layers \u001b[38;5;241m=\u001b[39m find_layers(model)\n\u001b[0;32m   1004\u001b[0m     ignore_layers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head_name] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39moutside_layer_modules\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:433\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_config\u001b[1;34m(cls, config, **kwargs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    432\u001b[0m     repo_id \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mname_or_path\n\u001b[1;32m--> 433\u001b[0m model_class \u001b[38;5;241m=\u001b[39m \u001b[43mget_class_from_dynamic_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    435\u001b[0m _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\dynamic_module_utils.py:553\u001b[0m, in \u001b[0;36mget_class_from_dynamic_module\u001b[1;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;66;03m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[0;32m    541\u001b[0m final_module \u001b[38;5;241m=\u001b[39m get_cached_module_file(\n\u001b[0;32m    542\u001b[0m     repo_id,\n\u001b[0;32m    543\u001b[0m     module_file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    551\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    552\u001b[0m )\n\u001b[1;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_class_in_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\dynamic_module_utils.py:250\u001b[0m, in \u001b[0;36mget_class_in_module\u001b[1;34m(class_name, module_path, force_reload)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# reload in both cases, unless the module is already imported and the hash hits\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__transformers_module_hash__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m module_hash:\n\u001b[1;32m--> 250\u001b[0m     \u001b[43mmodule_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     module\u001b[38;5;241m.\u001b[39m__transformers_module_hash__ \u001b[38;5;241m=\u001b[39m module_hash\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, class_name)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\togethercomputer\\LLaMA-2-7B-32K\\46c24bb5aef59722fa7aa6d75e832afd1d64b980\\modeling_flash_llama.py:49\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     flash_attn_v2_installed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease install Flash Attention: `pip install flash-attn --no-build-isolation`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflash_attn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrotary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_rotary_emb_func\n",
      "\u001b[1;31mImportError\u001b[0m: Please install Flash Attention: `pip install flash-attn --no-build-isolation`"
     ]
    }
   ],
   "source": [
    "main()\n",
    "print(\"this worked?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement bitsandbytes-cpu (from versions: none)\n",
      "ERROR: No matching distribution found for bitsandbytes-cpu\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install bitsandbytes-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantized model\n",
    "\n",
    "import os\n",
    "import json\n",
    "from outlines import models, generate\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from enum import Enum\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''\n",
    "\n",
    "\n",
    "# double_quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True)\n",
    "\n",
    "class model_class:\n",
    "    def __init__(self, model_name):\n",
    "        # Configure 4-bit quantization\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float32,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            llm_int8_enable_fp32_cpu_offload=True\n",
    "        )\n",
    "\n",
    "        # Load model with 4-bit quantization\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"cpu\",  # Force CPU usage\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float32\n",
    "        )\n",
    "        self.model = model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "class ForcedGenerationQuantized:\n",
    "   \n",
    "    def __init__(self, model_name):\n",
    "        self.openai = models.openai(\"gpt-4o\", api_key = os.environ[\"OPENAI_API_KEY\"])\n",
    "        model = model_class(model_name)\n",
    "        self.llm = models.transformers(model)    \n",
    "        self.generator = generate.choice(self.llm, [\"500\", \"0\", \"1000\", \"INFINITE\", \"100\"])\n",
    "        self.openaigenerator = generate.choice(self.openai, [\"500\", \"0\", \"1000\", \"INFINITE\", \"100\"])\n",
    "        self.completed_json = {\n",
    "            \"12:00AM-12:59AM\": -1,\n",
    "            \"1:00AM-1:59AM\": -1,\n",
    "            \"2:00AM-2:59AM\": -1,\n",
    "            \"3:00AM-3:59AM\": -1,\n",
    "            \"4:00AM-4:59AM\": -1,\n",
    "            \"5:00AM-5:59AM\": -1,\n",
    "            \"6:00AM-6:59AM\": -1,\n",
    "            \"7:00AM-7:59AM\": -1,\n",
    "            \"8:00AM-8:59AM\": -1,\n",
    "            \"9:00AM-9:59AM\": -1,\n",
    "            \"10:00AM-10:59AM\": -1,\n",
    "            \"11:00AM-11:59AM\": -1,\n",
    "            \"12:00PM-12:59PM\": -1,\n",
    "            \"1:00PM-1:59PM\": -1,\n",
    "            \"2:00PM-2:59PM\": -1,\n",
    "            \"3:00PM-3:59PM\": -1,\n",
    "            \"4:00PM-4:59PM\": -1,\n",
    "            \"5:00PM-5:59PM\": -1,\n",
    "            \"6:00PM-6:59PM\": -1,\n",
    "            \"7:00PM-7:59PM\": -1,\n",
    "            \"8:00PM-8:59PM\": -1,\n",
    "            \"9:00PM-9:59PM\": -1,\n",
    "            \"10:00PM-10:59PM\": -1,\n",
    "            \"11:00PM-11:59PM\": -1\n",
    "        }\n",
    "        print(\"generator loaded\")\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "            # self.target_token_ids = [self.tokenizer.encode(token) for token in self.completed_array]\n",
    "    def gen_context(self, prompt, time):\n",
    "        return \"\"\"\n",
    "\n",
    "        \n",
    "        You are an intelligent assistant that determines the cost associated with scheduling activities for a specific hour of the day. Your task is to assess the given hour in context and assign a cost from the predefined options: [\"0\", \"100\", \"500\", \"1000\", \"INFINITE\"].\n",
    "\n",
    "        Task Description:\n",
    "        Generate 24-hour cost table that aligns with natural language constraints and preferences for scheduling activities.\n",
    "\n",
    "        - Certain times are completely unavailable (e.g., sleep, existing meetings) which should have \"INFINITE\" cost.\n",
    "        - Some times are less ideal (e.g., early morning or late evening) which should have a cost of \"100\", \"500\", or \"1000\".\n",
    "        - Certain times are optimal for scheduling activities which should have a cost of 0.\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        Description:  From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.  \n",
    "        Specified Hour: 1:00AM-1:59AM\n",
    "        Output: \"1000\"  \n",
    "\n",
    "        Description: From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.\n",
    "        Specified Hour: 2:00PM-2:59PM  \n",
    "        Output: \"0\"  \n",
    "\n",
    "        Description: From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.  \n",
    "        Specified Hour: 10:00PM-10:59PM  \n",
    "        Output: \"500\"  \n",
    "\n",
    "\n",
    "        \n",
    "        Given the following description, determine the cost for the specified hour:\n",
    "\n",
    "        Description: {prompt}  \n",
    "        Specified Hour: {time}  \n",
    "\n",
    "        # Hard Constraints:\n",
    "        1. Only select a cost from [\"0\", \"100\", \"500\", \"1000\", \"INFINITE\"].\n",
    "        2. Always evaluate and assign a cost based on the specific hour, without inferring across multiple hours.\n",
    "        3. The output should only be the cost value in quotes.\n",
    "\n",
    "        Output:\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    def call(self, prompt):\n",
    "        sentence_so_far = \"\"\n",
    "        keys = list(self.completed_json.keys())\n",
    "\n",
    "        for hour in keys:\n",
    "            # Add the current hour's description to the context\n",
    "            sentence_so_far = self.gen_context(prompt, hour)\n",
    "            gen = None\n",
    "            openai_gen = None\n",
    "            # Use the generator to compute the cost\n",
    "            try:\n",
    "                gen = self.generator(sentence_so_far, max_tokens=3)\n",
    "                print(f\"Generated (Transformer): {gen}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error with Transformer generation: {e}\")\n",
    "                gen = \"500\"  # Fallback cost in case of error\n",
    "\n",
    "            try:\n",
    "                openai_gen = self.openaigenerator(sentence_so_far, max_tokens=3)\n",
    "                print(f\"Generated (OpenAI): {openai_gen}\")\n",
    "                cost = int(openai_gen.strip())\n",
    "            except ValueError:\n",
    "                print(f\"Invalid cost generated by OpenAI: {openai_gen}. Defaulting to Transformer cost.\")\n",
    "                cost = int(gen.strip())\n",
    "            except Exception as e:\n",
    "                print(f\"Error with OpenAI generation: {e}. Defaulting to 500.\")\n",
    "                cost = 500  # Fallback cost in case of error\n",
    "\n",
    "            # Save the generated cost for the current hour\n",
    "            self.completed_json[hour] = gen\n",
    "\n",
    "        # Return the completed JSON as a string\n",
    "        return json.dumps(self.completed_json, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    prompt = \"From 12:00 AM to 7:59 AM, these hours are available but less ideal for a doctor's appointment, resulting in a high cost of 200. Between 8:00 AM and 11:59 AM, work constraints render scheduling impossible, with an INFINITE cost. From 12:00 PM to 12:59 PM, this hour is optimal for a doctor's appointment, with a cost of 0. Between 1:00 PM and 4:59 PM, work hours make scheduling unavailable, resulting in an INFINITE cost. From 5:00 PM to 8:59 PM, this period is flexible and available, so the cost is 0. Finally, from 9:00 PM to 11:59 PM, late hours are less ideal for a doctor's appointment, resulting in a high cost of 500.\"\n",
    "    model = \"HuggingFaceH4/zephyr-7b-alpha\"\n",
    "    # model = \"facebook/opt-iml-max-1.3b\"\n",
    "    gen = ForcedGenerationQuantized(model)\n",
    "    result = gen.call(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuggingFaceH4/zephyr-7b-alpha\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# model = \"facebook/opt-iml-max-1.3b\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[43mForcedGenerationQuantized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m result \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39mcall(prompt)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[17], line 46\u001b[0m, in \u001b[0;36mForcedGenerationQuantized.__init__\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mopenai(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 46\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mtransformers(model)    \n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator \u001b[38;5;241m=\u001b[39m generate\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m500\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFINITE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[17], line 30\u001b[0m, in \u001b[0;36mmodel_class.__init__\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m     21\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[0;32m     22\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     23\u001b[0m     bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     llm_int8_enable_fp32_cpu_offload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Load model with 4-bit quantization\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Force CPU usage\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m     38\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3669\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3666\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3669\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3675\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3676\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[0;32m   3677\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:82\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.validate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n\u001b[0;32m     81\u001b[0m bnb_multibackend_is_enabled \u001b[38;5;241m=\u001b[39m is_bitsandbytes_multi_backend_available()\n\u001b[1;32m---> 82\u001b[0m \u001b[43mvalidate_bnb_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_flax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sure the weights are in PyTorch format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:558\u001b[0m, in \u001b[0;36mvalidate_bnb_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_multi_backend_available():\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _validate_bnb_multi_backend_availability(raise_exception)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_validate_bnb_cuda_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:536\u001b[0m, in \u001b[0;36m_validate_bnb_cuda_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exception:\n\u001b[0;32m    535\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(log_msg)\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(log_msg)\n\u001b[0;32m    538\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(log_msg)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
